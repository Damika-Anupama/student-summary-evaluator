{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5225cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:56:23.294857Z",
     "iopub.status.busy": "2023-08-30T11:56:23.294484Z",
     "iopub.status.idle": "2023-08-30T11:56:23.306638Z",
     "shell.execute_reply": "2023-08-30T11:56:23.305442Z"
    },
    "papermill": {
     "duration": 0.029044,
     "end_time": "2023-08-30T11:56:23.309140",
     "exception": false,
     "start_time": "2023-08-30T11:56:23.280096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the input summary here\n",
    "prompt_id = \"ebad26\"\n",
    "student_id = \"20003432\"\n",
    "input_summary = 'Meat packing industrees had many ways to get customers to buy the rotten, or spoiled meat. One of the ways the employees would conceal the rotten meat was by rubbing soda on it. The soda would cover, or get rid of that smell. Uptown Sinclair says \"Jonas had told them how the meat that was taken out of pickle would often be found sour, and how they would rub it up with soda to take away the smell, and sell it to be eaten on free-lunch counters.\" The meat packing industries were so desperate to make money and strive in buisness that they would sell anything, no matter the condition. In the Jungle it also says \"and fancy skinned hams  which were made of the oldest hogs, whose skins were so heavy and coarse that no one would buy them-that is, until they had been cooked and chopped fine and labeled head cheese\" The meatpacking industries would do many things to excell in buissness; other processes they developed were called \"boneless hams,\" and also \"California hams.\"  In conclusion, Meat packing industrees had many ways to get customers to buy the rotten, or spoiled meat.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1937239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:56:23.330583Z",
     "iopub.status.busy": "2023-08-30T11:56:23.330168Z",
     "iopub.status.idle": "2023-08-30T11:56:53.055199Z",
     "shell.execute_reply": "2023-08-30T11:56:53.053993Z"
    },
    "papermill": {
     "duration": 29.738885,
     "end_time": "2023-08-30T11:56:53.058043",
     "exception": false,
     "start_time": "2023-08-30T11:56:23.319158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\r\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622383 sha256=e9c55aa37c8985765dff67ec20985e82ed22e325e7afeac00c93257b729378f1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\r\n",
      "Successfully built autocorrect\r\n",
      "Installing collected packages: autocorrect\r\n",
      "Successfully installed autocorrect-2.6.1\r\n",
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a714491",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-30T11:56:53.083487Z",
     "iopub.status.busy": "2023-08-30T11:56:53.083030Z",
     "iopub.status.idle": "2023-08-30T11:57:10.768487Z",
     "shell.execute_reply": "2023-08-30T11:57:10.767637Z"
    },
    "papermill": {
     "duration": 17.701437,
     "end_time": "2023-08-30T11:57:10.771207",
     "exception": false,
     "start_time": "2023-08-30T11:56:53.069770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6600be0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:10.796788Z",
     "iopub.status.busy": "2023-08-30T11:57:10.795958Z",
     "iopub.status.idle": "2023-08-30T11:57:10.818568Z",
     "shell.execute_reply": "2023-08-30T11:57:10.817673Z"
    },
    "papermill": {
     "duration": 0.038348,
     "end_time": "2023-08-30T11:57:10.821443",
     "exception": false,
     "start_time": "2023-08-30T11:57:10.783095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d778f5fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:10.847026Z",
     "iopub.status.busy": "2023-08-30T11:57:10.846271Z",
     "iopub.status.idle": "2023-08-30T11:57:10.870596Z",
     "shell.execute_reply": "2023-08-30T11:57:10.869776Z"
    },
    "papermill": {
     "duration": 0.039597,
     "end_time": "2023-08-30T11:57:10.872807",
     "exception": false,
     "start_time": "2023-08-30T11:57:10.833210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "              prompt_title                                        prompt_text  \n",
       "3  Excerpt from The Jungle  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_test = prompts_test[prompts_test['prompt_id'] == prompt_id]\n",
    "prompts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac4204b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:10.898642Z",
     "iopub.status.busy": "2023-08-30T11:57:10.897756Z",
     "iopub.status.idle": "2023-08-30T11:57:10.912586Z",
     "shell.execute_reply": "2023-08-30T11:57:10.911560Z"
    },
    "papermill": {
     "duration": 0.030095,
     "end_time": "2023-08-30T11:57:10.914898",
     "exception": false,
     "start_time": "2023-08-30T11:57:10.884803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003432</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Meat packing industrees had many ways to get c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id prompt_id                                               text\n",
       "0   20003432    ebad26  Meat packing industrees had many ways to get c..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_record = {'student_id': student_id, 'prompt_id': prompt_id, 'text': input_summary}\n",
    "summaries_test = summaries_test.drop(summaries_test.index)\n",
    "summaries_test = summaries_test.append(input_record, ignore_index = True)\n",
    "summaries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e810e7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:10.940212Z",
     "iopub.status.busy": "2023-08-30T11:57:10.939926Z",
     "iopub.status.idle": "2023-08-30T11:57:10.947472Z",
     "shell.execute_reply": "2023-08-30T11:57:10.946563Z"
    },
    "papermill": {
     "duration": 0.022986,
     "end_time": "2023-08-30T11:57:10.949816",
     "exception": false,
     "start_time": "2023-08-30T11:57:10.926830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"debertav3base\"\n",
    "    learning_rate=1.5e-5\n",
    "    weight_decay=0.02\n",
    "    hidden_dropout_prob=0.007\n",
    "    attention_probs_dropout_prob=0.007\n",
    "    num_train_epochs=5\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4b920d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:10.976233Z",
     "iopub.status.busy": "2023-08-30T11:57:10.975691Z",
     "iopub.status.idle": "2023-08-30T11:57:10.986309Z",
     "shell.execute_reply": "2023-08-30T11:57:10.985206Z"
    },
    "papermill": {
     "duration": 0.026935,
     "end_time": "2023-08-30T11:57:10.988990",
     "exception": false,
     "start_time": "2023-08-30T11:57:10.962055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c230414d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:11.015113Z",
     "iopub.status.busy": "2023-08-30T11:57:11.014807Z",
     "iopub.status.idle": "2023-08-30T11:57:14.064049Z",
     "shell.execute_reply": "2023-08-30T11:57:14.062772Z"
    },
    "papermill": {
     "duration": 3.066185,
     "end_time": "2023-08-30T11:57:14.067078",
     "exception": false,
     "start_time": "2023-08-30T11:57:11.000893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.twd = TreebankWordDetokenizer()\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.spellchecker = SpellChecker() \n",
    "        \n",
    "    def word_overlap_count(self, row):\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "            \n",
    "    def ngrams(self, token, n):\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
    "        # Tokenize the original text and summary into words\n",
    "        original_tokens = row['prompt_tokens']\n",
    "        summary_tokens = row['summary_tokens']\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
    "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str):\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text):\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
    "        self.spellchecker.word_frequency.load_words(tokens)\n",
    "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame:\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "        \n",
    "        # Add prompt tokens into spelling checker dictionary\n",
    "        prompts[\"prompt_tokens\"].apply(\n",
    "            lambda x: self.add_spelling_dictionary(x)\n",
    "        )\n",
    "        \n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        # fix misspelling\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.speller(x)\n",
    "        )\n",
    "        \n",
    "        # count misspelling\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "        \n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
    "        \n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b63d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:14.093103Z",
     "iopub.status.busy": "2023-08-30T11:57:14.092790Z",
     "iopub.status.idle": "2023-08-30T11:57:14.674367Z",
     "shell.execute_reply": "2023-08-30T11:57:14.672837Z"
    },
    "papermill": {
     "duration": 0.597465,
     "end_time": "2023-08-30T11:57:14.676577",
     "exception": false,
     "start_time": "2023-08-30T11:57:14.079112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 821.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 427.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 503.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 540.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 715.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>bigram_overlap_ratio</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>trigram_overlap_ratio</th>\n",
       "      <th>quotes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003432</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Meat packing industrees had many ways to get c...</td>\n",
       "      <td>220</td>\n",
       "      <td>Meat packing industries had many ways to get c...</td>\n",
       "      <td>25</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1076</td>\n",
       "      <td>0.204461</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>0.39726</td>\n",
       "      <td>73</td>\n",
       "      <td>0.334862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id prompt_id                                               text  \\\n",
       "0   20003432    ebad26  Meat packing industrees had many ways to get c...   \n",
       "\n",
       "   summary_length                                 fixed_summary_text  \\\n",
       "0             220  Meat packing industries had many ways to get c...   \n",
       "\n",
       "   splling_err_num                                    prompt_question  \\\n",
       "0               25  Summarize the various ways the factory would u...   \n",
       "\n",
       "              prompt_title                                        prompt_text  \\\n",
       "0  Excerpt from The Jungle  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "   prompt_length  length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
       "0           1076      0.204461                  28                    87   \n",
       "\n",
       "   bigram_overlap_ratio  trigram_overlap_count  trigram_overlap_ratio  \\\n",
       "0               0.39726                     73               0.334862   \n",
       "\n",
       "   quotes_count  \n",
       "0             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d196004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:14.705879Z",
     "iopub.status.busy": "2023-08-30T11:57:14.705609Z",
     "iopub.status.idle": "2023-08-30T11:57:15.069624Z",
     "shell.execute_reply": "2023-08-30T11:57:15.068636Z"
    },
    "papermill": {
     "duration": 0.381537,
     "end_time": "2023-08-30T11:57:15.072112",
     "exception": false,
     "start_time": "2023-08-30T11:57:14.690575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37eb2aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:15.102926Z",
     "iopub.status.busy": "2023-08-30T11:57:15.102252Z",
     "iopub.status.idle": "2023-08-30T11:57:15.119969Z",
     "shell.execute_reply": "2023-08-30T11:57:15.118966Z"
    },
    "papermill": {
     "duration": 0.035221,
     "end_time": "2023-08-30T11:57:15.122315",
     "exception": false,
     "start_time": "2023-08-30T11:57:15.087094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DebertaRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                target: str,\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
    "        self.input_col = \"input\"\n",
    "        \n",
    "        self.text_cols = [self.input_col] \n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=42)\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return tokenized\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        in_text = (\n",
    "                    test_df[\"prompt_title\"] + sep \n",
    "                    + test_df[\"prompt_question\"] + sep \n",
    "                    + test_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        test_df[self.input_col] = in_text\n",
    "\n",
    "        test_ = test_df[[self.input_col]]\n",
    "    \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model_content.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(\"bert/\", str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 4,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model_content, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7061f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:15.151616Z",
     "iopub.status.busy": "2023-08-30T11:57:15.151323Z",
     "iopub.status.idle": "2023-08-30T11:57:15.160153Z",
     "shell.execute_reply": "2023-08-30T11:57:15.159153Z"
    },
    "papermill": {
     "duration": 0.0263,
     "end_time": "2023-08-30T11:57:15.162718",
     "exception": false,
     "start_time": "2023-08-30T11:57:15.136418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        if fold == 0:\n",
    "            model_dir =  f\"/kaggle/input/commonlit-deberta-model/deberta_models/{target}\"\n",
    "\n",
    "            csr = DebertaRegressor(\n",
    "                model_name=model_name,\n",
    "                target=target,\n",
    "                model_dir = model_dir, \n",
    "                hidden_dropout_prob=hidden_dropout_prob,\n",
    "                attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "                max_length=max_length,\n",
    "               )\n",
    "\n",
    "            pred = csr.predict(\n",
    "                test_df=test_df, \n",
    "                fold=fold\n",
    "            )\n",
    "        \n",
    "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c73285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:15.191741Z",
     "iopub.status.busy": "2023-08-30T11:57:15.191481Z",
     "iopub.status.idle": "2023-08-30T11:57:37.935089Z",
     "shell.execute_reply": "2023-08-30T11:57:37.933738Z"
    },
    "papermill": {
     "duration": 22.761163,
     "end_time": "2023-08-30T11:57:37.937588",
     "exception": false,
     "start_time": "2023-08-30T11:57:15.176425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "fold 2:\n",
      "fold 3:\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "fold 2:\n",
      "fold 3:\n"
     ]
    }
   ],
   "source": [
    "for target in [\"content\", \"wording\"]:\n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72279dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:37.968460Z",
     "iopub.status.busy": "2023-08-30T11:57:37.967961Z",
     "iopub.status.idle": "2023-08-30T11:57:37.992258Z",
     "shell.execute_reply": "2023-08-30T11:57:37.991340Z"
    },
    "papermill": {
     "duration": 0.042392,
     "end_time": "2023-08-30T11:57:37.994576",
     "exception": false,
     "start_time": "2023-08-30T11:57:37.952184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>...</th>\n",
       "      <th>content_pred_0</th>\n",
       "      <th>content_pred_1</th>\n",
       "      <th>content_pred_2</th>\n",
       "      <th>content_pred_3</th>\n",
       "      <th>content</th>\n",
       "      <th>wording_pred_0</th>\n",
       "      <th>wording_pred_1</th>\n",
       "      <th>wording_pred_2</th>\n",
       "      <th>wording_pred_3</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003432</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Meat packing industrees had many ways to get c...</td>\n",
       "      <td>220</td>\n",
       "      <td>Meat packing industries had many ways to get c...</td>\n",
       "      <td>25</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.091737</td>\n",
       "      <td>2.091737</td>\n",
       "      <td>2.091737</td>\n",
       "      <td>2.091737</td>\n",
       "      <td>2.091737</td>\n",
       "      <td>1.238747</td>\n",
       "      <td>1.238747</td>\n",
       "      <td>1.238747</td>\n",
       "      <td>1.238747</td>\n",
       "      <td>1.238747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id prompt_id                                               text  \\\n",
       "0   20003432    ebad26  Meat packing industrees had many ways to get c...   \n",
       "\n",
       "   summary_length                                 fixed_summary_text  \\\n",
       "0             220  Meat packing industries had many ways to get c...   \n",
       "\n",
       "   splling_err_num                                    prompt_question  \\\n",
       "0               25  Summarize the various ways the factory would u...   \n",
       "\n",
       "              prompt_title                                        prompt_text  \\\n",
       "0  Excerpt from The Jungle  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "   prompt_length  ...  content_pred_0  content_pred_1  content_pred_2  \\\n",
       "0           1076  ...        2.091737        2.091737        2.091737   \n",
       "\n",
       "   content_pred_3   content  wording_pred_0  wording_pred_1 wording_pred_2  \\\n",
       "0        2.091737  2.091737        1.238747        1.238747       1.238747   \n",
       "\n",
       "   wording_pred_3   wording  \n",
       "0        1.238747  1.238747  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71402db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.025765Z",
     "iopub.status.busy": "2023-08-30T11:57:38.025506Z",
     "iopub.status.idle": "2023-08-30T11:57:38.030635Z",
     "shell.execute_reply": "2023-08-30T11:57:38.029915Z"
    },
    "papermill": {
     "duration": 0.023533,
     "end_time": "2023-08-30T11:57:38.032782",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.009249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\n",
    "                #\"fold\", \n",
    "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\",\n",
    "                \"input\"\n",
    "               ] + [\n",
    "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ] + [\n",
    "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e21a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.064108Z",
     "iopub.status.busy": "2023-08-30T11:57:38.063829Z",
     "iopub.status.idle": "2023-08-30T11:57:38.199291Z",
     "shell.execute_reply": "2023-08-30T11:57:38.198462Z"
    },
    "papermill": {
     "duration": 0.153827,
     "end_time": "2023-08-30T11:57:38.201926",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.048099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"content\":[],\n",
    "    \"wording\":[]\n",
    "}\n",
    "\n",
    "for target in targets:\n",
    "    for i in range(CFG.n_splits):\n",
    "        common_path = f\"/kaggle/input/commonlit-lgbm-model/lgbm_models/{target}/lgbr_base_{i}.txt\"\n",
    "        loaded_model = lgb.Booster(model_file=common_path)\n",
    "        model_dict[target].append(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd9925a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.233063Z",
     "iopub.status.busy": "2023-08-30T11:57:38.232754Z",
     "iopub.status.idle": "2023-08-30T11:57:38.257249Z",
     "shell.execute_reply": "2023-08-30T11:57:38.256467Z"
    },
    "papermill": {
     "duration": 0.043087,
     "end_time": "2023-08-30T11:57:38.260008",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.216921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "    preds = []\n",
    "\n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = test.drop(columns=drop_columns)\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    pred_dict[target] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3640119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.291848Z",
     "iopub.status.busy": "2023-08-30T11:57:38.290837Z",
     "iopub.status.idle": "2023-08-30T11:57:38.302168Z",
     "shell.execute_reply": "2023-08-30T11:57:38.301337Z"
    },
    "papermill": {
     "duration": 0.029947,
     "end_time": "2023-08-30T11:57:38.304690",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.274743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    preds = pred_dict[target]\n",
    "    for i, pred in enumerate(preds):\n",
    "        test[f\"{target}_pred_{i}\"] = pred\n",
    "\n",
    "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adf50c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.337197Z",
     "iopub.status.busy": "2023-08-30T11:57:38.336137Z",
     "iopub.status.idle": "2023-08-30T11:57:38.360534Z",
     "shell.execute_reply": "2023-08-30T11:57:38.359461Z"
    },
    "papermill": {
     "duration": 0.043191,
     "end_time": "2023-08-30T11:57:38.363137",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.319946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>...</th>\n",
       "      <th>content_pred_0</th>\n",
       "      <th>content_pred_1</th>\n",
       "      <th>content_pred_2</th>\n",
       "      <th>content_pred_3</th>\n",
       "      <th>content</th>\n",
       "      <th>wording_pred_0</th>\n",
       "      <th>wording_pred_1</th>\n",
       "      <th>wording_pred_2</th>\n",
       "      <th>wording_pred_3</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003432</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Meat packing industrees had many ways to get c...</td>\n",
       "      <td>220</td>\n",
       "      <td>Meat packing industries had many ways to get c...</td>\n",
       "      <td>25</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857889</td>\n",
       "      <td>1.961615</td>\n",
       "      <td>2.0107</td>\n",
       "      <td>2.038331</td>\n",
       "      <td>1.967134</td>\n",
       "      <td>1.286987</td>\n",
       "      <td>1.427863</td>\n",
       "      <td>0.982915</td>\n",
       "      <td>1.330573</td>\n",
       "      <td>1.257085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id prompt_id                                               text  \\\n",
       "0   20003432    ebad26  Meat packing industrees had many ways to get c...   \n",
       "\n",
       "   summary_length                                 fixed_summary_text  \\\n",
       "0             220  Meat packing industries had many ways to get c...   \n",
       "\n",
       "   splling_err_num                                    prompt_question  \\\n",
       "0               25  Summarize the various ways the factory would u...   \n",
       "\n",
       "              prompt_title                                        prompt_text  \\\n",
       "0  Excerpt from The Jungle  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "   prompt_length  ...  content_pred_0  content_pred_1  content_pred_2  \\\n",
       "0           1076  ...        1.857889        1.961615          2.0107   \n",
       "\n",
       "   content_pred_3   content  wording_pred_0  wording_pred_1 wording_pred_2  \\\n",
       "0        2.038331  1.967134        1.286987        1.427863       0.982915   \n",
       "\n",
       "   wording_pred_3   wording  \n",
       "0        1.330573  1.257085  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "951458a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T11:57:38.395419Z",
     "iopub.status.busy": "2023-08-30T11:57:38.394792Z",
     "iopub.status.idle": "2023-08-30T11:57:38.406514Z",
     "shell.execute_reply": "2023-08-30T11:57:38.405441Z"
    },
    "papermill": {
     "duration": 0.030473,
     "end_time": "2023-08-30T11:57:38.408842",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.378369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003432</td>\n",
       "      <td>1.967134</td>\n",
       "      <td>1.257085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id   content   wording\n",
       "0   20003432  1.967134  1.257085"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86397a",
   "metadata": {
    "papermill": {
     "duration": 0.015038,
     "end_time": "2023-08-30T11:57:38.439241",
     "exception": false,
     "start_time": "2023-08-30T11:57:38.424203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 88.692989,
   "end_time": "2023-08-30T11:57:41.147674",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-30T11:56:12.454685",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
